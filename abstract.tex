\begin{abstract}

Reinforcement learning was recently successfully used for real-world robotic
manipulation tasks, without the need for human demonstration, using a
\textit{normalized advantage function}-algorithm (NAF). Limitations on the
shape of the advantage function however poses doubts to what kind of policies
can be learned using this method. For similar tasks, convolutional neural
networks have been used for pose estimation from images taken with
fixed-position cameras. For some applications however, this might not be a
valid assumption. It was also shown that the quality of policies for robotic
tasks severely deteriorates from small camera offsets.  This thesis
investigates the use of NAF for a pushing task with clear multi-modal
properties. The results are compared with using a deterministic policy with
minimal constraints on the Q-function surface. Methods for pose estimation
using convolutional neural networks are further investigated, especially with
regards to randomly placed cameras with unknown offsets. By defining the
coordinate frame of objects with respect to some visible feature, it is
hypothesized that relative pose estimation can be accomplished even when the
camera is not fixed and the offset is unknown. NAF is successfully implemented
to solve a simple reaching task on a real robotic system where data collection
is distributed over several robots, and learning is done on a separate server.
Using NAF to learn a pushing task fails to converge to a good policy, both on
the real robots and in simulation. Deep deterministic policy gradient (DDPG) is
instead used in simulation and successfully learns to solve the task. The
learned policy is then applied on the real robots and accomplishes to solve the
task in the real setting as well. Pose estimation from fixed position camera
images is learned and the policy is still able to solve the task using these
estimates. By defining a coordinate frame from an object visible to the camera,
in this case the robot arm, a neural network learns to regress the pushable
objects pose in this frame without the assumption of a fixed camera. However,
the precision of the predictions were too inaccurate to be used for solving the
pushing task. Further modifications to this approach could however show to be a
feasible solution to randomly placed cameras with unknown poses.

\end{abstract}


\begin{otherlanguage}{swedish}
    \begin{abstract}

        Reinforcement learning har nyligen använts framgångsrikt för att lära
        icke-simulerade robotar uppgifter med hjälp av en \textit{normalized
        advantage function}-algoritm (NAF), detta utan att använda mänskliga
        demonstrationer.  Restriktioner på funktionsytorna som använts kan dock
        visa sig vara problematiska för generalisering till andra uppgifter.
        För pose-estimering har i liknande sammanhang convolutional neural
        networks använts med bilder från kamera med konstant position. I vissa
        applikationer kan dock inte kameran garanteras hålla en konstant
        position och studier har visat att kvaliteten på policys kraftigt
        förvärras när kameran förflyttas. Denna uppsats undersöker användandet
        av NAF för att lära in en ''pushing''-uppgift med tydliga multimodala
        egenskaper. Resultaten jämförs med användandet av en deterministisk
        policy med minimala restriktioner på Q-funktionsytan. Vidare undersöks
        användandet av convolutional neural networks för pose-estimering,
        särskilt med hänsyn till slumpmässigt placerade kameror med okänd
        placering. Genom att definiera koordinatramen för objekt i förhållande
        till ett synligt referensobjekt så tros relativ pose-estimering kunna
        utföras även när kameran är rörlig och förflyttningen är okänd. NAF
        appliceras i denna uppsats framgångsrikt på enklare problem där
        datainsamling är distribuerad över flera robotar och inlärning sker på
        en central server. Vid applicering på ''pushing''-uppgiften misslyckas
        dock NAF, både vid träning på riktiga robotar och i simulering. Deep
        deterministic policy gradient (DDPG) appliceras istället på problemet
        och lär sig framgångsrikt att lösa problemet i simulering.  Den inlärda
        policyn appliceras sedan framgångsrikt på riktiga robotar.
        Pose-estimering genom att använda en fast kamera implementeras också
        framgångsrikt. Genom att definiera ett koordinatsystem från ett föremål
        i bilden med känd position, i detta fall robotarmen, kan andra föremåls
        positioner beskrivas i denna koordinatram med hjälp av neurala nätverk.
        Dock så visar sig precisionen vara för låg för att appliceras på
        robotar. Resultaten visar ändå att denna metod, med ytterligare
        utökningar och modifikationer, skulle kunna lösa problemet.

    \end{abstract}
\end{otherlanguage}
